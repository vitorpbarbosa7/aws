{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 SageMaker Invoke Endpoint\n",
    "# This example shows how to invoke SageMaker Endpoint from outside of AWS environment using Boto3 SDK\n",
    "# Boto is the Amazon Web Services (AWS) SDK for Python\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/index.html\n",
    "\n",
    "# Endpoint: XGBoost - Kaggle Bike Rental - Regressor Trained in XGBoost Lectures\n",
    "# Makesure Endpoint is deployed before running this example\n",
    "# \n",
    "# Reference:\n",
    "#  https://github.com/awslabs/amazon-sagemaker-examples\n",
    "\n",
    "# NOTE: SageMaker SDK now requires additional permissions DescribeEndpoint, DescribeEndpointConfig in-addition to InvokeEndpoint\n",
    "#   boto3 SDK requires just InvokeEndpoint permission.\n",
    "#   Please update SageMakerInvokeEndpoint permissions to reflect this policy document:\n",
    "#   Logon with my_admin account and update permissions (IAM->Policies->SageMakerInvokeEndpoint->Edit Policy)\n",
    "#   \n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:DescribeEndpointConfig\",\n",
    "                \"sagemaker:DescribeEndpoint\",\n",
    "                \"sagemaker:InvokeEndpoint\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import math\n",
    "import dateutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a session with AWS\n",
    "# Specify credentials and region to be used for this session.\n",
    "# We will use a ml_user_predict credentials that has limited privileges\n",
    "boto_session = boto3.Session(profile_name='ml_user_predict',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accessanalyzer', 'account', 'acm', 'acm-pca', 'alexaforbusiness', 'amp', 'amplify', 'amplifybackend', 'amplifyuibuilder', 'apigateway', 'apigatewaymanagementapi', 'apigatewayv2', 'appconfig', 'appconfigdata', 'appflow', 'appintegrations', 'application-autoscaling', 'application-insights', 'applicationcostprofiler', 'appmesh', 'apprunner', 'appstream', 'appsync', 'athena', 'auditmanager', 'autoscaling', 'autoscaling-plans', 'backup', 'backup-gateway', 'batch', 'billingconductor', 'braket', 'budgets', 'ce', 'chime', 'chime-sdk-identity', 'chime-sdk-meetings', 'chime-sdk-messaging', 'cloud9', 'cloudcontrol', 'clouddirectory', 'cloudformation', 'cloudfront', 'cloudhsm', 'cloudhsmv2', 'cloudsearch', 'cloudsearchdomain', 'cloudtrail', 'cloudwatch', 'codeartifact', 'codebuild', 'codecommit', 'codedeploy', 'codeguru-reviewer', 'codeguruprofiler', 'codepipeline', 'codestar', 'codestar-connections', 'codestar-notifications', 'cognito-identity', 'cognito-idp', 'cognito-sync', 'comprehend', 'comprehendmedical', 'compute-optimizer', 'config', 'connect', 'connect-contact-lens', 'connectparticipant', 'cur', 'customer-profiles', 'databrew', 'dataexchange', 'datapipeline', 'datasync', 'dax', 'detective', 'devicefarm', 'devops-guru', 'directconnect', 'discovery', 'dlm', 'dms', 'docdb', 'drs', 'ds', 'dynamodb', 'dynamodbstreams', 'ebs', 'ec2', 'ec2-instance-connect', 'ecr', 'ecr-public', 'ecs', 'efs', 'eks', 'elastic-inference', 'elasticache', 'elasticbeanstalk', 'elastictranscoder', 'elb', 'elbv2', 'emr', 'emr-containers', 'es', 'events', 'evidently', 'finspace', 'finspace-data', 'firehose', 'fis', 'fms', 'forecast', 'forecastquery', 'frauddetector', 'fsx', 'gamelift', 'gamesparks', 'glacier', 'globalaccelerator', 'glue', 'grafana', 'greengrass', 'greengrassv2', 'groundstation', 'guardduty', 'health', 'healthlake', 'honeycode', 'iam', 'identitystore', 'imagebuilder', 'importexport', 'inspector', 'inspector2', 'iot', 'iot-data', 'iot-jobs-data', 'iot1click-devices', 'iot1click-projects', 'iotanalytics', 'iotdeviceadvisor', 'iotevents', 'iotevents-data', 'iotfleethub', 'iotsecuretunneling', 'iotsitewise', 'iotthingsgraph', 'iottwinmaker', 'iotwireless', 'ivs', 'kafka', 'kafkaconnect', 'kendra', 'keyspaces', 'kinesis', 'kinesis-video-archived-media', 'kinesis-video-media', 'kinesis-video-signaling', 'kinesisanalytics', 'kinesisanalyticsv2', 'kinesisvideo', 'kms', 'lakeformation', 'lambda', 'lex-models', 'lex-runtime', 'lexv2-models', 'lexv2-runtime', 'license-manager', 'lightsail', 'location', 'logs', 'lookoutequipment', 'lookoutmetrics', 'lookoutvision', 'machinelearning', 'macie', 'macie2', 'managedblockchain', 'marketplace-catalog', 'marketplace-entitlement', 'marketplacecommerceanalytics', 'mediaconnect', 'mediaconvert', 'medialive', 'mediapackage', 'mediapackage-vod', 'mediastore', 'mediastore-data', 'mediatailor', 'memorydb', 'meteringmarketplace', 'mgh', 'mgn', 'migration-hub-refactor-spaces', 'migrationhub-config', 'migrationhubstrategy', 'mobile', 'mq', 'mturk', 'mwaa', 'neptune', 'network-firewall', 'networkmanager', 'nimble', 'opensearch', 'opsworks', 'opsworkscm', 'organizations', 'outposts', 'panorama', 'personalize', 'personalize-events', 'personalize-runtime', 'pi', 'pinpoint', 'pinpoint-email', 'pinpoint-sms-voice', 'pinpoint-sms-voice-v2', 'polly', 'pricing', 'proton', 'qldb', 'qldb-session', 'quicksight', 'ram', 'rbin', 'rds', 'rds-data', 'redshift', 'redshift-data', 'rekognition', 'resiliencehub', 'resource-groups', 'resourcegroupstaggingapi', 'robomaker', 'route53', 'route53-recovery-cluster', 'route53-recovery-control-config', 'route53-recovery-readiness', 'route53domains', 'route53resolver', 'rum', 's3', 's3control', 's3outposts', 'sagemaker', 'sagemaker-a2i-runtime', 'sagemaker-edge', 'sagemaker-featurestore-runtime', 'sagemaker-runtime', 'savingsplans', 'schemas', 'sdb', 'secretsmanager', 'securityhub', 'serverlessrepo', 'service-quotas', 'servicecatalog', 'servicecatalog-appregistry', 'servicediscovery', 'ses', 'sesv2', 'shield', 'signer', 'sms', 'sms-voice', 'snow-device-management', 'snowball', 'sns', 'sqs', 'ssm', 'ssm-contacts', 'ssm-incidents', 'sso', 'sso-admin', 'sso-oidc', 'stepfunctions', 'storagegateway', 'sts', 'support', 'swf', 'synthetics', 'textract', 'timestream-query', 'timestream-write', 'transcribe', 'transfer', 'translate', 'voice-id', 'waf', 'waf-regional', 'wafv2', 'wellarchitected', 'wisdom', 'workdocs', 'worklink', 'workmail', 'workmailmessageflow', 'workspaces', 'workspaces-web', 'xray']\n"
     ]
    }
   ],
   "source": [
    "# List of low level clients that are available in boto3\n",
    "print(boto_session.get_available_services())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire a SageMaker Runtime client for us-east-1 region\n",
    "client = boto_session.client(service_name='sagemaker-runtime',region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Your Endpoint Name\n",
    "endpoint_name = 'xgboost-biketrain-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data\n",
    "#datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "# Actual=562\n",
    "sample_one = '2012-12-19 17:00:00,4,0,1,1,16.4,20.455,50,26.0027'\n",
    "# Actual=569\n",
    "sample_two = '2012-12-19 18:00:00,4,0,1,1,15.58,19.695,50,23.9994'\n",
    "# Actual=4\n",
    "sample_three = '2012-12-10 01:00:00,4,0,1,2,14.76,18.94,100,0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Structure: \n",
    "# datetime,season,holiday,workingday,weather,temp,atemp,humidity,windspeed,casual,registered,count\n",
    "\n",
    "# Model expects data in this format (it was trained with these features):\n",
    "# season,holiday,workingday,weather,temp,atemp,humidity,windspeed,year,month,day,dayofweek,hour\n",
    "\n",
    "def transform_data(data):\n",
    "    features = data.split(',')\n",
    "    \n",
    "    # Extract year, month, day, dayofweek, hour\n",
    "    dt = dateutil.parser.parse(features[0])\n",
    "\n",
    "    features.append(str(dt.year))\n",
    "    features.append(str(dt.month))\n",
    "    features.append(str(dt.day))\n",
    "    features.append(str(dt.weekday()))\n",
    "    features.append(str(dt.hour))\n",
    "    \n",
    "    # Return the transformed data. skip datetime field\n",
    "    return ','.join(features[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:\n",
      " 2012-12-19 17:00:00,4,0,1,1,16.4,20.455,50,26.0027\n",
      "Transformed Data:\n",
      " 4,0,1,1,16.4,20.455,50,26.0027,2012,12,19,2,17\n"
     ]
    }
   ],
   "source": [
    "print('Raw Data:\\n',sample_one)\n",
    "print('Transformed Data:\\n',transform_data(sample_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's invoke prediction now\n",
    "result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=transform_data(sample_one).encode('utf-8'),\n",
    "                       ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.349300861358643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Count 571.092597122044\n"
     ]
    }
   ],
   "source": [
    "# Actual Count is 562...but predicted is 6.36.\n",
    "\n",
    "# Model was trained with log1p(count)\n",
    "# So, we need to apply inverse transformation to get the actual count\n",
    "# Predicted Count looks much better now\n",
    "print ('Predicted Count', math.expm1(float(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,0,1,1,16.4,20.455,50,26.0027,2012,12,19,2,17\n",
      "4,0,1,1,15.58,19.695,50,23.9994,2012,12,19,2,18\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([transform_data(sample_one),transform_data(sample_two)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction for multiple observations in the same call\n",
    "result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=('\\n'.join([transform_data(sample_one),\n",
    "                                        transform_data(sample_two)]).encode('utf-8')),\n",
    "                       ContentType='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.349300861358643\\n6.321451187133789\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Prediction\n",
    "# Transform data and invoke prediction in specified batch sizes\n",
    "def run_predictions(data, batch_size):\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    transformed_data = [transform_data(row.strip()) for row in data]\n",
    "    \n",
    "    # Splitting using regular expression as xgboost 1-2-2 is returning\n",
    "    # predicted values with inconsistent delimiters (comma, newline or both)\n",
    "\n",
    "    # pattern looks for one or more of non-numeric characters\n",
    "    pattern = r'[^0-9.]+'\n",
    "\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        \n",
    "        print(i,i+batch_size)\n",
    "        \n",
    "        result = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                       Body=('\\n'.join(transformed_data[i : i + batch_size]).encode('utf-8')),\n",
    "                       ContentType='text/csv')\n",
    "        \n",
    "        result = result['Body'].read().decode('utf-8')\n",
    "        result = re.split(pattern,result)\n",
    "                \n",
    "        predictions += [math.expm1(float(r)) for r in result if r != \"\"]\n",
    "                \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[571.092597122044, 555.3798181158465, 10.489585991183136]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_predictions([sample_one,sample_two,sample_three],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a batch prediction on Test.CSV File\n",
    "# Read the file content\n",
    "data = []\n",
    "with open('test.csv','r') as f:\n",
    "    # skip header\n",
    "    f.readline()\n",
    "    # Read remaining lines\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n",
      "100 200\n",
      "200 300\n",
      "300 400\n",
      "400 500\n",
      "500 600\n",
      "600 700\n",
      "700 800\n",
      "800 900\n",
      "900 1000\n",
      "1000 1100\n",
      "1100 1200\n",
      "1200 1300\n",
      "1300 1400\n",
      "1400 1500\n",
      "1500 1600\n",
      "1600 1700\n",
      "1700 1800\n",
      "1800 1900\n",
      "1900 2000\n",
      "2000 2100\n",
      "2100 2200\n",
      "2200 2300\n",
      "2300 2400\n",
      "2400 2500\n",
      "2500 2600\n",
      "2600 2700\n",
      "2700 2800\n",
      "2800 2900\n",
      "2900 3000\n",
      "3000 3100\n",
      "3100 3200\n",
      "3200 3300\n",
      "3300 3400\n",
      "3400 3500\n",
      "3500 3600\n",
      "3600 3700\n",
      "3700 3800\n",
      "3800 3900\n",
      "3900 4000\n",
      "4000 4100\n",
      "4100 4200\n",
      "4200 4300\n",
      "4300 4400\n",
      "4400 4500\n",
      "4500 4600\n",
      "4600 4700\n",
      "4700 4800\n",
      "4800 4900\n",
      "4900 5000\n",
      "5000 5100\n",
      "5100 5200\n",
      "5200 5300\n",
      "5300 5400\n",
      "5400 5500\n",
      "5500 5600\n",
      "5600 5700\n",
      "5700 5800\n",
      "5800 5900\n",
      "5900 6000\n",
      "6000 6100\n",
      "6100 6200\n",
      "6200 6300\n",
      "6300 6400\n",
      "6400 6500\n",
      "Wall time: 7.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = run_predictions(data,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6493, 6493)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions),len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d83c50586832a6e66958999177b9690593214b6421a3b3b66343c1b4742b286"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
